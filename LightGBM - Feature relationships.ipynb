{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Feature Relationships\n",
    "\n",
    "This workbook outlines a repeatable process you can use to view feature relationships for a binary classificaiton, with the code being reasonably easy to adapt to other scenarios. In this case we use a simple (non-cross-validated) light GBM model, but the model itself is easily replacable with say a random forest or XGBoost.\n",
    "\n",
    "Note: All data preperation including dealing with categorical variables has been performed in a previous workbook. This script is purely for the model and output creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package import\n",
    "\n",
    "Import all the required packages for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Import necessary packages\n",
    "###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, roc_auc_score,confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the variables\n",
    "\n",
    "Here we outline all the variables used to run the script:\n",
    "\n",
    "path = the path to the folder that holds the dataset\n",
    "\n",
    "dataset_name = the name of the dataset to train and test the model\n",
    "\n",
    "target = the name of the column that is your binary target variable\n",
    "\n",
    "test_frac = the fraction of the dataset that will be set aside for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to data & name of the file\n",
    "path = \"C:/Users/andrew.davidson/OneDrive - Concentra Consulting Limited/Documents/Projects/GBT Feature Relationships/KK Box/data/\"\n",
    "\n",
    "dataset_name = \"Prepped Data.csv\"\n",
    "\n",
    "# The column name of the target variable\n",
    "target_name = \"Churn\"\n",
    "pred_prob_name = target_name + \" Probability\"\n",
    "\n",
    "# Define the size of the test set\n",
    "test_frac = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset import\n",
    "Using the pre-defined path, import the dataset of your choice.\n",
    "\n",
    "Here, the dataset contains both the train & test data which we later split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>bd</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>total_payment_plan_days</th>\n",
       "      <th>avg_payment_plan_days</th>\n",
       "      <th>plan_net_worth</th>\n",
       "      <th>mean_payment_each_transaction</th>\n",
       "      <th>total_actual_payment</th>\n",
       "      <th>auto_renew_times</th>\n",
       "      <th>cancel_times</th>\n",
       "      <th>...</th>\n",
       "      <th>no_transactions_flag</th>\n",
       "      <th>city_mean</th>\n",
       "      <th>normal_payment_method_id_mean</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>registered_via_3.0</th>\n",
       "      <th>registered_via_4.0</th>\n",
       "      <th>registered_via_7.0</th>\n",
       "      <th>registered_via_9.0</th>\n",
       "      <th>registered_via_13.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>180.0000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123023</td>\n",
       "      <td>0.085326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.93624</td>\n",
       "      <td>67.36879</td>\n",
       "      <td>300.0000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>300.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123023</td>\n",
       "      <td>0.921790</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>115.93624</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>517.9374</td>\n",
       "      <td>149.0</td>\n",
       "      <td>514.92377</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064056</td>\n",
       "      <td>0.033369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.93624</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>517.9374</td>\n",
       "      <td>99.0</td>\n",
       "      <td>514.92377</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123023</td>\n",
       "      <td>0.033369</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn    bd  transaction_count  total_payment_plan_days  \\\n",
       "0      1  28.0                0.0                      NaN   \n",
       "1      1  20.0                1.0                 30.00000   \n",
       "2      1  18.0                2.0                115.93624   \n",
       "3      1   NaN               10.0                115.93624   \n",
       "4      1  35.0                8.0                115.93624   \n",
       "\n",
       "   avg_payment_plan_days  plan_net_worth  mean_payment_each_transaction  \\\n",
       "0                    NaN             NaN                            NaN   \n",
       "1               30.00000        180.0000                          180.0   \n",
       "2               67.36879        300.0000                          150.0   \n",
       "3               30.00000        517.9374                          149.0   \n",
       "4               30.00000        517.9374                           99.0   \n",
       "\n",
       "   total_actual_payment  auto_renew_times  cancel_times  ...  \\\n",
       "0                   NaN               NaN           NaN  ...   \n",
       "1             180.00000               0.0           0.0  ...   \n",
       "2             300.00000               0.0           0.0  ...   \n",
       "3             514.92377              10.0           0.0  ...   \n",
       "4             514.92377               8.0           1.0  ...   \n",
       "\n",
       "   no_transactions_flag  city_mean  normal_payment_method_id_mean  \\\n",
       "0                     1   0.131997                            NaN   \n",
       "1                     0   0.123023                       0.085326   \n",
       "2                     0   0.123023                       0.921790   \n",
       "3                     0   0.064056                       0.033369   \n",
       "4                     0   0.123023                       0.033369   \n",
       "\n",
       "   gender_female  gender_male  registered_via_3.0  registered_via_4.0  \\\n",
       "0              0            1                   1                   0   \n",
       "1              0            1                   1                   0   \n",
       "2              0            1                   1                   0   \n",
       "3              0            0                   0                   0   \n",
       "4              1            0                   0                   0   \n",
       "\n",
       "   registered_via_7.0  registered_via_9.0  registered_via_13.0  \n",
       "0                   0                   0                    0  \n",
       "1                   0                   0                    0  \n",
       "2                   0                   0                    0  \n",
       "3                   1                   0                    0  \n",
       "4                   1                   0                    0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in df\n",
    "df = pd.read_csv(path + dataset_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into a test train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(target_name, axis = 1)\n",
    "y = df[target_name]\n",
    "\n",
    "#Spit into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "Define the model & fit it to the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', importance_type='gain', learning_rate=0.01,\n",
       "               max_depth=3, n_estimators=300, num_leaves=32, subsample=0.5,\n",
       "               subsample_for_bin=500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model:\n",
    "\n",
    "# Define the mode params\n",
    "# Note: we do not cross validate in this script for simplicity\n",
    "params = {'num_leaves': 32,\n",
    "                'max_depth': 3,\n",
    "                 'learning_rate': 0.01,\n",
    "                 'n_estimators' : 300,\n",
    "                'subsample_for_bin': 500,\n",
    "                 'min_child_samples': 20,\n",
    "                'subsample': 0.5}\n",
    "\n",
    "model= lgb.LGBMClassifier(num_leaves = params[\"num_leaves\"],\n",
    "                         max_depth = params[\"max_depth\"],\n",
    "                         learning_rate =params[\"learning_rate\"],\n",
    "                         n_estimators = params[\"n_estimators\"],\n",
    "                         subsample_for_bin = params[\"subsample_for_bin\"],\n",
    "                         min_child_samples = params[\"min_child_samples\"],\n",
    "                         subsample = params[\"subsample\"],\n",
    "                         #n_jobs = -1,\n",
    "                         boosting_type = 'dart',\n",
    "                          # Set the feature importance type to \"gain\"\n",
    "                        importance_type = \"gain\")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and prediction probabilities\n",
    "Extract the predictions and prediction probabilities of the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC:  0.95\n",
      "Accuracy:  97.0\n",
      "[[217964   3000]\n",
      " [  4868  16908]]\n"
     ]
    }
   ],
   "source": [
    "# Extract test predictions from the model\n",
    "preds = model.predict(X_test)\n",
    "# Extract the test prediction probabilities from the model\n",
    "test_probs = model.predict_proba(X_test)[:,1]\n",
    "# Calculate the ROC score, accuracy and confusion matrix for the test set\n",
    "print('ROC: ', round(roc_auc_score(y_test, test_probs),2))\n",
    "print('Accuracy: ', round(accuracy_score(y_test, (test_probs>0.5).astype(int)),2)*100)\n",
    "print(confusion_matrix(y_test, (test_probs>0.5).astype(int)))\n",
    "\n",
    "# Extract the predicted probability from the test set\n",
    "probs_series = pd.Series(test_probs, index = X_test.index).rename(pred_prob_name)\n",
    "\n",
    "# Add the target column & the predictions to the test set\n",
    "test_output = pd.concat([X_test, y_test, probs_series], axis=1, sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model feature importances\n",
    "\n",
    "Extract the overall feature importances from the model. This was pre-set to be information gain when setting up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "      <th>Importance_Norm</th>\n",
       "      <th>ImportanceRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_payment_plan_days</td>\n",
       "      <td>1.720945e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cancel_times</td>\n",
       "      <td>6.145042e+06</td>\n",
       "      <td>0.357074</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>auto_renew_times</td>\n",
       "      <td>7.247692e+05</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>day_diff_last_listen__first_listen</td>\n",
       "      <td>7.105501e+05</td>\n",
       "      <td>0.041288</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>day_diff_membership_expire__last_listen</td>\n",
       "      <td>5.578413e+05</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Feature    Importance  Importance_Norm  \\\n",
       "2                   total_payment_plan_days  1.720945e+07         1.000000   \n",
       "8                              cancel_times  6.145042e+06         0.357074   \n",
       "7                          auto_renew_times  7.247692e+05         0.042115   \n",
       "28       day_diff_last_listen__first_listen  7.105501e+05         0.041288   \n",
       "27  day_diff_membership_expire__last_listen  5.578413e+05         0.032415   \n",
       "\n",
       "    ImportanceRank  \n",
       "2              1.0  \n",
       "8              2.0  \n",
       "7              3.0  \n",
       "28             4.0  \n",
       "27             5.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pandas series containing all the feature importances\n",
    "feat_importance = pd.Series(model.feature_importances_, index = X_train.columns)\n",
    "# Create a dataframe for feature importances with normalised importance & rank\n",
    "feat_df = pd.DataFrame(feat_importance, columns = [\"Importance\"]).reset_index().rename({'index' : \"Feature\"}, axis = 1)\n",
    "feat_df[\"Importance_Norm\"] = feat_df[\"Importance\"]/ max(feat_df[\"Importance\"])\n",
    "feat_df[\"ImportanceRank\"] = feat_df.Importance.rank(ascending = False)\n",
    "feat_df.sort_values(\"ImportanceRank\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Feature Contributions\n",
    "\n",
    "Derive the model feature contributions for every row in our dataset. We do this by using the \"predict_proba\" method on our model and feeding it our test data. We can extract the prediction probabilties for the training and the test data. However, we are only using the test set for this example due to the size of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Get the feature contributions for every row\n",
    "drivers_df = model.predict_proba(X_test, pred_contrib=True)\n",
    "\n",
    "# Create a dataframe using the contributions\n",
    "drivers_df = pd.DataFrame(drivers_df,\n",
    "                              columns = list(X_test.columns) + ['<BIAS>'],\n",
    "                              index = X_test.index)\n",
    "\n",
    "# Reshape the contribution df\n",
    "contribs = drivers_df.reset_index().melt(id_vars = \"index\")\n",
    "values = X_test.reset_index().melt(id_vars = \"index\")\n",
    "\n",
    "#Join the values & their contributions\n",
    "driver_output = contribs.merge(values, how='left', \n",
    "                               left_on = ['index','variable'], \n",
    "                               right_on = ['index', 'variable'])\n",
    "\n",
    "driver_output = driver_output.rename({'variable' : \"Feature\",\n",
    "                                          'value_x' : 'Contribution',\n",
    "                                          'value_y' : 'Value'}, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "Create the output needed to plot the ROC curve in Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FalsePositiveRate</th>\n",
       "      <th>TruePositiveRate</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Model</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.775619</td>\n",
       "      <td>Model</td>\n",
       "      <td>0.948991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.775619</td>\n",
       "      <td>Model</td>\n",
       "      <td>0.948991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.774420</td>\n",
       "      <td>Model</td>\n",
       "      <td>0.948991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.771652</td>\n",
       "      <td>Model</td>\n",
       "      <td>0.948991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.770439</td>\n",
       "      <td>Model</td>\n",
       "      <td>0.948991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FalsePositiveRate  TruePositiveRate  Threshold  Model  auc_score\n",
       "0           0.000000          0.000000   1.775619  Model   0.948991\n",
       "1           0.000000          0.001286   0.775619  Model   0.948991\n",
       "2           0.000000          0.002526   0.774420  Model   0.948991\n",
       "3           0.000000          0.003352   0.771652  Model   0.948991\n",
       "4           0.000005          0.005006   0.770439  Model   0.948991"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresh = roc_curve(test_output[\"Churn\"], test_output[\"Churn Probability\"])\n",
    "auc = roc_auc_score(test_output[\"Churn\"], test_output[\"Churn Probability\"])\n",
    "\n",
    "roc_data = pd.DataFrame({'FalsePositiveRate': fpr, 'TruePositiveRate': tpr, \"Threshold\": thresh})\n",
    "roc_data[\"Model\"] = \"Model\"\n",
    "roc_data[\"auc_score\"] = auc\n",
    "\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(test_output))]\n",
    "ns_fpr, ns_tpr, _ = roc_curve(test_output[\"Churn\"], ns_probs)\n",
    "ns_roc_data = pd.DataFrame({'FalsePositiveRate': ns_fpr, 'TruePositiveRate': ns_tpr, \"Threshold\": _})\n",
    "ns_roc_data[\"Model\"] = \"Naive Prediction\"\n",
    "roc_output = pd.concat([roc_data, ns_roc_data])\n",
    "roc_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final output\n",
    "Write the outputs as csv's into the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.to_csv(path + \"Test Set Predictions.csv\")\n",
    "feat_df.to_csv(path + \"Feature Importances.csv\", index = False)\n",
    "driver_output.to_csv(path + \"Feature Contributions.csv\", index = False)\n",
    "roc_output.to_csv(path + \"ROC Curve.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
